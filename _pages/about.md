---
title: "Who I Am"
layout: single
permalink: /about/
author_profile: true   # shows your avatar + socials from _config.yml
toc: false
---

<!-- Hero -->
<section style="margin-bottom:1.25rem">
  <h1 style="margin:0">Hi, Iâ€™m Sanuwar ðŸ‘‹</h1>
  <p style="font-size:1.05rem; margin-top:.5rem;">
    Sr. Automation & AI Engineer focused on <strong>agentic RAG</strong>, <strong>LLM evaluation & guardrails</strong>, and <strong>MLOps/CI</strong>.
    I build reliable AI systems that actually ship: eval loops in CI, data/quality gates, and internal copilots that reduce toil.
  </p>
</section>

{% include feature_row id="about-highlights" type="left" %}

### What I do in one line
Ship AI features with measurable reliability â€” from retrieval quality and prompts to evals, regressions, and rollout.

### Experience at a glance
- **Sr. Automation & AI Engineer, Humana (2020â€”Present):** led AI testing frameworks, agent workflows, dashboards; emphasis on LLM evals, guardrails, and CI integration.  
- **Software Engineer (Backend), Verizon (2018â€”2020):** APIs, SQL/ORM, reliability.  
- **Ph.D., Consumer & Design Sciences (Auburn):** research design & statistics; published in *Vaccine* and others.

### Focus areas
- Agentic RAG (retrievers, memory, tool-calling), evaluation harnesses (gold sets, judges, regression gates)  
- MLOps/CI for LLM apps (pipelines, canary + offline/online evals, prompt/version control)  
- Vector stores & search (OpenSearch, Pinecone), orchestration (n8n/Flowise), AWS/GCP

### Stacks I reach for
<code>Python</code> <code>SQL</code> <code>AWS & Bedrock</code> <code>GCP & Vertex</code> <code>OpenSearch</code> <code>LangChain</code> <code>Airflow</code> <code>SageMaker</code> <code>Guardrails/Evals</code>

> Want to collaborate or compare notes?  
[Letâ€™s Talk â†’](/contact/)
